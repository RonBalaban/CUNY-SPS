{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2c32a75-dbcc-41f0-9bfc-86f2c76f178d",
   "metadata": {},
   "source": [
    "### Instructions \n",
    "\n",
    "### Using any of the three classifiers (Decision Tree, Naive Bayes Classifier, Maximum Entropy Classifiers) described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. \n",
    "\n",
    "#### Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set (used to perform error analysis), and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. \n",
    "\n",
    "### How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect? \n",
    "\n",
    "### Source: Natural Language Processing with Python, exercise 6.10.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f99010-255f-4ab1-9cac-f11fb9f04f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\Ron\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import library\n",
    "import nltk\n",
    "nltk.download('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35ce7f6-57c7-41aa-9498-1d486e7616b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 6944\n",
      "Dev-test set: 500\n",
      "Test set: 500\n",
      "Example training samples: [('Carina', 'female'), ('Reena', 'female'), ('Connie', 'male'), ('Ev', 'male'), ('Madelin', 'female'), ('Alvina', 'female'), ('Jacynth', 'female'), ('Tobin', 'male'), ('Tessy', 'female'), ('Xymenes', 'male'), ('Onida', 'female'), ('Marti', 'female'), ('Adriena', 'female'), ('Julio', 'male'), ('Joseph', 'male'), ('Berk', 'male'), ('Deeanne', 'female'), ('Schuyler', 'male'), ('Kaylee', 'female'), ('Ariela', 'female'), ('Kali', 'female'), ('Corina', 'female'), ('Ajay', 'female'), ('Casandra', 'female'), ('Shena', 'female')]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from nltk.corpus import names\n",
    "\n",
    "# Load and label names\n",
    "male_names = [(name, 'male') for name in names.words('male.txt')]\n",
    "female_names = [(name, 'female') for name in names.words('female.txt')]\n",
    "\n",
    "# Combine and shuffle\n",
    "all_names = male_names + female_names\n",
    "random.shuffle(all_names)\n",
    "\n",
    "# Split into subsets\n",
    "test_names = all_names[:500]\n",
    "devtest_names = all_names[500:1000]\n",
    "train_names = all_names[1000:]   \n",
    "\n",
    "# Check counts\n",
    "print(f\"Training set: {len(train_names)}\")\n",
    "print(f\"Dev-test set: {len(devtest_names)}\")\n",
    "print(f\"Test set: {len(test_names)}\")\n",
    "\n",
    "# Glimpse training set\n",
    "print(\"Example training samples:\", train_names[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcef244-1209-4143-ba77-11d562a1f462",
   "metadata": {},
   "source": [
    "### With the NTLK library and names corpus made, along with the subset splitting done, I will move to simple classification and eventual gradual improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cab6a0cf-3771-4527-b7ba-37db16373e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development test accuracy: 75.2%\n",
      "Final test accuracy: 78.6%\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     40.4 : 1.0\n",
      "             last_letter = 'k'              male : female =     25.9 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.9 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.2 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.7 : 1.0\n",
      "             last_letter = 'm'              male : female =      8.7 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.2 : 1.0\n",
      "             last_letter = 'v'              male : female =      7.8 : 1.0\n",
      "             last_letter = 'r'              male : female =      7.1 : 1.0\n",
      "             last_letter = 'g'              male : female =      5.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "# Define simple feature extractor \n",
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1].lower()}\n",
    "\n",
    "# Create subsets\n",
    "train_set = [(gender_features(name), gender) for (name, gender) in train_names]\n",
    "devtest_set = [(gender_features(name), gender) for (name, gender) in devtest_names]\n",
    "test_set = [(gender_features(name), gender) for (name, gender) in test_names]\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evaluate \n",
    "devtest_accuracy = accuracy(classifier, devtest_set)\n",
    "test_accuracy = accuracy(classifier, test_set)\n",
    "\n",
    "# See metrics\n",
    "print(f\"Development test accuracy: {devtest_accuracy *100:.1f}%\")\n",
    "print(f\"Final test accuracy: {test_accuracy * 100:.1f}%\")\n",
    "\n",
    "# Most important letter features \n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89033bf-2b0d-4d7b-8ea1-4e9d6901a9d6",
   "metadata": {},
   "source": [
    "### With this initial classifier, which has a decent accuracy rating of 75.2% and 78.6% for the Dev-Test and Final accuracy, this proves a solid baseline result. The Dev-Test accuracy is how well the model performs on the tuning data, and the final accuracy is against the test data. We can identify the ratio of certain letters to determine which names are more likely to be male or female. Let's see where the classificer makes mistakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bba6ece-2cc3-4beb-9d06-703bf86847b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 124 out of 500\n",
      "\n",
      "Sample Name Misclassifications:\n",
      "\n",
      "Abagail         - predicted: male   | actual: female\n",
      "Adel            - predicted: male   | actual: female\n",
      "Allah           - predicted: female | actual: male\n",
      "Amabel          - predicted: male   | actual: female\n",
      "Aurel           - predicted: male   | actual: female\n",
      "Bab             - predicted: male   | actual: female\n",
      "Barnabe         - predicted: female | actual: male\n",
      "Bell            - predicted: male   | actual: female\n",
      "Benjy           - predicted: female | actual: male\n",
      "Benny           - predicted: female | actual: male\n",
      "Berkley         - predicted: female | actual: male\n",
      "Bren            - predicted: male   | actual: female\n",
      "Brice           - predicted: female | actual: male\n",
      "Brinkley        - predicted: female | actual: male\n",
      "Candis          - predicted: male   | actual: female\n",
      "Carmel          - predicted: male   | actual: female\n",
      "Charleen        - predicted: male   | actual: female\n",
      "Chauncey        - predicted: female | actual: male\n",
      "Christal        - predicted: male   | actual: female\n",
      "Cortese         - predicted: female | actual: male\n",
      "Dallas          - predicted: male   | actual: female\n",
      "Darby           - predicted: female | actual: male\n",
      "Daryle          - predicted: female | actual: male\n",
      "Davide          - predicted: female | actual: male\n",
      "Dennie          - predicted: female | actual: male\n"
     ]
    }
   ],
   "source": [
    "# See name by name on Dev-Test set, and which it classified wrong\n",
    "errors = []\n",
    "\n",
    "for (name, true_label) in devtest_names:\n",
    "    guess = classifier.classify(gender_features(name))\n",
    "    if guess != true_label:\n",
    "        errors.append((true_label, guess, name))\n",
    "\n",
    "# Sort errors alphabetically\n",
    "errors = sorted(errors, key=lambda x: x[2])\n",
    "\n",
    "print(f\"Number of errors: {len(errors)} out of {len(devtest_names)}\")\n",
    "print(\"\\nSample Name Misclassifications:\\n\")\n",
    "\n",
    "for (true_label, guess, name) in errors[:25]:\n",
    "    print(f\"{name:15} - predicted: {guess:6} | actual: {true_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1413815-373e-42a3-8728-8e46886b0b8c",
   "metadata": {},
   "source": [
    "### The classifier struggled with female names ending in consonants, such as Abigail, Bell, Charleen, and Christal. Conversely, it struggled with male names ending with vowels, such as Benjy, Benny, Brice, Daryle, and Davide. Some names are too ambiguous or rare, such as Sam, Alex, Dallas, Darby, and Allah, so the model cannot learn the actual gender well from them, as the name either rarely appears or could be for either gender. The last letter rule defined earlier doesn't always hold up, so I need to enhance the feature focus. Chapter 6, Section 1.2 enhances the classifier to capture the first and last letters to determine prefix/suffix patterns. However, as the book notes, it introduces a lot more features and can lead to overfitting. This leads to a higher training accuracy, but lower accuracy for the dev-test and test sets. So I will avoid making too much of a change on the feature training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f797504-0c3f-4c6a-8977-4ff108638769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development test accuracy: 78.2%$\n",
      "Final test accuracy: 82.2%\n",
      "Most Informative Features\n",
      "                last_two = 'na'           female : male   =     96.1 : 1.0\n",
      "                last_two = 'ia'           female : male   =     86.4 : 1.0\n",
      "             last_letter = 'a'            female : male   =     40.4 : 1.0\n",
      "                last_two = 'us'             male : female =     37.6 : 1.0\n",
      "                last_two = 'ra'           female : male   =     36.7 : 1.0\n",
      "                last_two = 'sa'           female : male   =     31.1 : 1.0\n",
      "                last_two = 'ta'           female : male   =     30.0 : 1.0\n",
      "                last_two = 'do'             male : female =     26.1 : 1.0\n",
      "             last_letter = 'k'              male : female =     25.9 : 1.0\n",
      "                last_two = 'ld'             male : female =     23.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Modified version of gender_features2 in Chapter 6.1.2\n",
    "def gender_features3(name):\n",
    "    features = {\n",
    "        'first_letter': name[0].lower(),\n",
    "        'last_letter': name[-1].lower(),\n",
    "        'last_two': name[-2:].lower(),   \n",
    "        'name_length': len(name)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "\n",
    "# Create sets using the new features\n",
    "train_set3 = [(gender_features3(name), gender) for (name, gender) in train_names]\n",
    "devtest_set3 = [(gender_features3(name), gender) for (name, gender) in devtest_names]\n",
    "test_set3 = [(gender_features3(name), gender) for (name, gender) in test_names]\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "classifier3 = NaiveBayesClassifier.train(train_set3)\n",
    "\n",
    "# Evaluate \n",
    "devtest_accuracy3 = accuracy(classifier3, devtest_set3)\n",
    "test_accuracy3 = accuracy(classifier3, test_set3)\n",
    "\n",
    "# See metrics\n",
    "print(f\"Development test accuracy: {devtest_accuracy3 *100:.1f}%$\")\n",
    "print(f\"Final test accuracy: {test_accuracy3 * 100:.1f}%\")\n",
    "\n",
    "\n",
    "# Most important letter features \n",
    "classifier3.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f281041-405e-491a-884b-9cde3a182f0a",
   "metadata": {},
   "source": [
    "### With this enhancement, the classifier now considers the last 2 letters of a name as its own feature, leading to an increase in accuracy from 75.2% to 78.2%, and from 78.6% to 82.2% respectively. We can see that we went from 124/500 errors in the prior method, to 109/500 errors below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf08b4d0-29de-4690-b0bf-f056fecd5e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 109 out of 500\n",
      "\n",
      "Sample Name Misclassifications:\n",
      "\n",
      "Abagail         - predicted: male   | actual: female\n",
      "Adel            - predicted: male   | actual: female\n",
      "Allah           - predicted: female | actual: male\n",
      "Amabel          - predicted: male   | actual: female\n",
      "Aurel           - predicted: male   | actual: female\n",
      "Bab             - predicted: male   | actual: female\n",
      "Barbey          - predicted: male   | actual: female\n",
      "Barnabe         - predicted: female | actual: male\n",
      "Bell            - predicted: male   | actual: female\n",
      "Benny           - predicted: female | actual: male\n",
      "Bren            - predicted: male   | actual: female\n",
      "Brice           - predicted: female | actual: male\n",
      "Bryn            - predicted: female | actual: male\n",
      "Candis          - predicted: male   | actual: female\n",
      "Carmel          - predicted: male   | actual: female\n",
      "Chauncey        - predicted: female | actual: male\n",
      "Cortese         - predicted: female | actual: male\n",
      "Dallas          - predicted: male   | actual: female\n",
      "Darby           - predicted: female | actual: male\n",
      "Daryle          - predicted: female | actual: male\n",
      "Davide          - predicted: female | actual: male\n",
      "Dennie          - predicted: female | actual: male\n",
      "Dwayne          - predicted: female | actual: male\n",
      "Eddy            - predicted: female | actual: male\n",
      "Eustace         - predicted: female | actual: male\n"
     ]
    }
   ],
   "source": [
    "errors3 = []\n",
    "\n",
    "for (name, true_label) in devtest_names:\n",
    "    guess = classifier3.classify(gender_features3(name))\n",
    "    if guess != true_label:\n",
    "        errors3.append((true_label, guess, name))\n",
    "\n",
    "# Sort errors alphabetically\n",
    "errors3 = sorted(errors3, key=lambda x: x[2])\n",
    "\n",
    "print(f\"Number of errors: {len(errors3)} out of {len(devtest_names)}\")\n",
    "print(\"\\nSample Name Misclassifications:\\n\")\n",
    "\n",
    "for (true_label, guess, name) in errors3[:25]:\n",
    "    print(f\"{name:15} - predicted: {guess:6} | actual: {true_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be9526-9348-48d9-8802-95111f91d728",
   "metadata": {},
   "source": [
    "### The remaining tricky names are the following edge cases: \n",
    "\n",
    "    - Female names ending with consonants: Abagail, Amabel, Bell, Carmel, Candis\n",
    "    - Male names ending with vowels: Benny, Davide, Eddy, Dwayne\n",
    "    - Rare or ambiguous names: Allah, Barnabe, Cortese, Darby\n",
    "\n",
    "### So adding the last 2 letters as a suffix feature helped the classifier, but it still has issues with the above categories. I will add the first 2 letters as a feature as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d36c64c-a67b-460e-8abe-61bc4898ce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development test accuracy: 79.2%\n",
      "Final test accuracy: 82.2%\n",
      "Most Informative Features\n",
      "                last_two = 'na'           female : male   =     96.1 : 1.0\n",
      "                last_two = 'ia'           female : male   =     86.4 : 1.0\n",
      "             last_letter = 'a'            female : male   =     40.4 : 1.0\n",
      "                last_two = 'us'             male : female =     37.6 : 1.0\n",
      "                last_two = 'ra'           female : male   =     36.7 : 1.0\n",
      "                last_two = 'sa'           female : male   =     31.1 : 1.0\n",
      "                last_two = 'ta'           female : male   =     30.0 : 1.0\n",
      "                last_two = 'do'             male : female =     26.1 : 1.0\n",
      "             last_letter = 'k'              male : female =     25.9 : 1.0\n",
      "                last_two = 'ld'             male : female =     23.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Modified version of gender_features3, adding first two letters\n",
    "def gender_features4(name):\n",
    "    features = {\n",
    "        'first_letter': name[0].lower(),\n",
    "        'first_two': name[:2].lower(),      \n",
    "        'last_letter': name[-1].lower(),\n",
    "        'last_two': name[-2:].lower(),      \n",
    "        'name_length': len(name)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "\n",
    "# Create sets using the new features\n",
    "train_set4 = [(gender_features4(name), gender) for (name, gender) in train_names]\n",
    "devtest_set4 = [(gender_features4(name), gender) for (name, gender) in devtest_names]\n",
    "test_set4 = [(gender_features4(name), gender) for (name, gender) in test_names]\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "classifier4 = NaiveBayesClassifier.train(train_set4)\n",
    "\n",
    "# Evaluate \n",
    "devtest_accuracy4 = accuracy(classifier4, devtest_set4)\n",
    "test_accuracy4 = accuracy(classifier4, test_set4)\n",
    "\n",
    "# See metrics\n",
    "print(f\"Development test accuracy: {devtest_accuracy4 * 100:.1f}%\")\n",
    "print(f\"Final test accuracy: {test_accuracy4 * 100:.1f}%\")\n",
    "\n",
    "# Most important letter features \n",
    "classifier4.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d565f3-d21b-4565-8479-d1d493926820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 104 out of 500\n",
      "\n",
      "Sample Name Misclassifications:\n",
      "\n",
      "Abagail         - predicted: male   | actual: female\n",
      "Adel            - predicted: male   | actual: female\n",
      "Allah           - predicted: female | actual: male\n",
      "Bab             - predicted: male   | actual: female\n",
      "Barbe           - predicted: male   | actual: female\n",
      "Barbey          - predicted: male   | actual: female\n",
      "Bell            - predicted: male   | actual: female\n",
      "Benjy           - predicted: female | actual: male\n",
      "Benny           - predicted: female | actual: male\n",
      "Berkley         - predicted: female | actual: male\n",
      "Bren            - predicted: male   | actual: female\n",
      "Brice           - predicted: female | actual: male\n",
      "Bryn            - predicted: female | actual: male\n",
      "Cal             - predicted: female | actual: male\n",
      "Chauncey        - predicted: female | actual: male\n",
      "Cortese         - predicted: female | actual: male\n",
      "Dallas          - predicted: male   | actual: female\n",
      "Darby           - predicted: female | actual: male\n",
      "Daryle          - predicted: female | actual: male\n",
      "Davide          - predicted: female | actual: male\n",
      "Dennie          - predicted: female | actual: male\n",
      "Eddy            - predicted: female | actual: male\n",
      "Esteban         - predicted: female | actual: male\n",
      "Eustace         - predicted: female | actual: male\n",
      "Gael            - predicted: male   | actual: female\n"
     ]
    }
   ],
   "source": [
    "# Check Errors\n",
    "errors4 = []\n",
    "\n",
    "for (name, true_label) in devtest_names:\n",
    "    guess = classifier4.classify(gender_features4(name))\n",
    "    if guess != true_label:\n",
    "        errors4.append((true_label, guess, name))\n",
    "\n",
    "# Sort errors alphabetically\n",
    "errors4 = sorted(errors4, key=lambda x: x[2])\n",
    "\n",
    "print(f\"Number of errors: {len(errors4)} out of {len(devtest_names)}\")\n",
    "print(\"\\nSample Name Misclassifications:\\n\")\n",
    "\n",
    "for (true_label, guess, name) in errors4[:25]:\n",
    "    print(f\"{name:15} - predicted: {guess:6} | actual: {true_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3bcf93-7059-4dea-a1a6-b27456143ce4",
   "metadata": {},
   "source": [
    "### Adding the first 2 letters improved the Dev-Test accuracy by 1%, and the test accuracy stayed the same. The number of errors went from 109 to 104, and the remaining ones are rare or ambiguous (Barbe, Bab, Brice, Cal, Cortese, Daryle, Gael). For additional improvement, I will check if there are any vowel/consonant patterns to add to the current features (length, prefix, and suffix). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cb70104-65c7-4c12-ba80-f293adee5f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development test accuracy: 77.2%\n",
      "Final test accuracy: 80.4%\n",
      "Most Informative Features\n",
      "                last_two = 'na'           female : male   =     96.1 : 1.0\n",
      "                last_two = 'ia'           female : male   =     86.4 : 1.0\n",
      "             last_letter = 'a'            female : male   =     40.4 : 1.0\n",
      "                last_two = 'us'             male : female =     37.6 : 1.0\n",
      "                last_two = 'ra'           female : male   =     36.7 : 1.0\n",
      "                last_two = 'sa'           female : male   =     31.1 : 1.0\n",
      "                last_two = 'ta'           female : male   =     30.0 : 1.0\n",
      "                last_two = 'do'             male : female =     26.1 : 1.0\n",
      "             last_letter = 'k'              male : female =     25.9 : 1.0\n",
      "                last_two = 'ld'             male : female =     23.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Adding vowel/consonant features\n",
    "def gender_features5(name):\n",
    "    vowels = 'aeiou'\n",
    "    name_lower = name.lower()\n",
    "    num_vowels = sum(1 for letter in name_lower if letter in vowels)\n",
    "    num_consonants = len(name_lower) - num_vowels\n",
    "    \n",
    "    features = {\n",
    "        'first_letter': name_lower[0],\n",
    "        'first_two': name_lower[:2],\n",
    "        'last_letter': name_lower[-1],\n",
    "        'last_two': name_lower[-2:],\n",
    "        'name_length': len(name_lower),\n",
    "        'num_vowels': num_vowels,\n",
    "        'num_consonants': num_consonants,\n",
    "        'ends_with_vowel': (name_lower[-1] in vowels),\n",
    "        'starts_with_vowel': (name_lower[0] in vowels)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "\n",
    "# Create sets using the new features\n",
    "train_set5 = [(gender_features5(name), gender) for (name, gender) in train_names]\n",
    "devtest_set5 = [(gender_features5(name), gender) for (name, gender) in devtest_names]\n",
    "test_set5 = [(gender_features5(name), gender) for (name, gender) in test_names]\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "classifier5 = NaiveBayesClassifier.train(train_set5)\n",
    "\n",
    "# Evaluate \n",
    "devtest_accuracy5 = accuracy(classifier5, devtest_set5)\n",
    "test_accuracy5 = accuracy(classifier5, test_set5)\n",
    "\n",
    "# See metrics\n",
    "print(f\"Development test accuracy: {devtest_accuracy5 * 100:.1f}%\")\n",
    "print(f\"Final test accuracy: {test_accuracy5 * 100:.1f}%\")\n",
    "\n",
    "# Most important letter features \n",
    "classifier5.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033541e7-a30f-4861-9265-fee58cb9fced",
   "metadata": {},
   "source": [
    "### Adding the Consonant/Vowel features lowered the Dev-Test accuracy from 79.2% to 77.2%, and the Final Test Accuracy from 82.2% to 80.4%, asd the Naive Bayes Classifier likely overfitted to these new features. This is likely because multiple features are highly correlated, such as num_vowels, ends_with_vowel, and last_letter. So simple, strong features, such as the suffix, prefix, and first/last letters, can outperform others in Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "551f54b8-fc70-42f7-910a-5e8b97e059b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 114 out of 500\n",
      "\n",
      "Sample Name Misclassifications:\n",
      "\n",
      "Abagail         - predicted: male   | actual: female\n",
      "Adel            - predicted: male   | actual: female\n",
      "Amabel          - predicted: male   | actual: female\n",
      "Bab             - predicted: male   | actual: female\n",
      "Barbey          - predicted: male   | actual: female\n",
      "Barnabe         - predicted: female | actual: male\n",
      "Beau            - predicted: female | actual: male\n",
      "Bell            - predicted: male   | actual: female\n",
      "Bren            - predicted: male   | actual: female\n",
      "Brice           - predicted: female | actual: male\n",
      "Candis          - predicted: male   | actual: female\n",
      "Carmel          - predicted: male   | actual: female\n",
      "Charleen        - predicted: male   | actual: female\n",
      "Chelsey         - predicted: male   | actual: female\n",
      "Christal        - predicted: male   | actual: female\n",
      "Corey           - predicted: male   | actual: female\n",
      "Cortese         - predicted: female | actual: male\n",
      "Dallas          - predicted: male   | actual: female\n",
      "Darsey          - predicted: male   | actual: female\n",
      "Daryle          - predicted: female | actual: male\n",
      "Davide          - predicted: female | actual: male\n",
      "Dennie          - predicted: female | actual: male\n",
      "Drake           - predicted: female | actual: male\n",
      "Dru             - predicted: female | actual: male\n",
      "Dwayne          - predicted: female | actual: male\n"
     ]
    }
   ],
   "source": [
    "errors5 = []\n",
    "\n",
    "for (name, true_label) in devtest_names:\n",
    "    guess = classifier5.classify(gender_features5(name))\n",
    "    if guess != true_label:\n",
    "        errors5.append((true_label, guess, name))\n",
    "\n",
    "# Sort errors alphabetically \n",
    "errors5 = sorted(errors5, key=lambda x: x[2])\n",
    "\n",
    "print(f\"Number of errors: {len(errors5)} out of {len(devtest_names)}\")\n",
    "print(\"\\nSample Name Misclassifications:\\n\")\n",
    "\n",
    "for (true_label, guess, name) in errors5[:25]:\n",
    "    print(f\"{name:15} - predicted: {guess:6} | actual: {true_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800aa1a5-1866-42d8-beda-f0fbe11ee4ce",
   "metadata": {},
   "source": [
    "### Since those features are highly correlated, I will remove the num_vowels and num_consonants features, and check if keeping the starts_with and ends_with features helps accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f66c8d7-0942-4ecd-9efd-44ea75f869df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development test accuracy: 77.2%\n",
      "Final test accuracy: 82.0%\n",
      "Most Informative Features\n",
      "                last_two = 'na'           female : male   =     96.1 : 1.0\n",
      "                last_two = 'ia'           female : male   =     86.4 : 1.0\n",
      "             last_letter = 'a'            female : male   =     40.4 : 1.0\n",
      "                last_two = 'us'             male : female =     37.6 : 1.0\n",
      "                last_two = 'ra'           female : male   =     36.7 : 1.0\n",
      "                last_two = 'sa'           female : male   =     31.1 : 1.0\n",
      "                last_two = 'ta'           female : male   =     30.0 : 1.0\n",
      "                last_two = 'do'             male : female =     26.1 : 1.0\n",
      "             last_letter = 'k'              male : female =     25.9 : 1.0\n",
      "                last_two = 'ld'             male : female =     23.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "def gender_features6(name):\n",
    "    vowels = 'aeiou'\n",
    "    name_lower = name.lower()\n",
    "    \n",
    "    features = {\n",
    "        'first_letter': name_lower[0],\n",
    "        'first_two': name_lower[:2],\n",
    "        'last_letter': name_lower[-1],\n",
    "        'last_two': name_lower[-2:],\n",
    "        'name_length': len(name_lower),\n",
    "        'starts_with_vowel': (name_lower[0] in vowels),\n",
    "        'ends_with_vowel': (name_lower[-1] in vowels)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "\n",
    "# Create sets using the new features\n",
    "train_set6 = [(gender_features6(name), gender) for (name, gender) in train_names]\n",
    "devtest_set6 = [(gender_features6(name), gender) for (name, gender) in devtest_names]\n",
    "test_set6 = [(gender_features6(name), gender) for (name, gender) in test_names]\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "classifier6 = NaiveBayesClassifier.train(train_set6)\n",
    "\n",
    "# Evaluate \n",
    "devtest_accuracy6 = accuracy(classifier6, devtest_set6)\n",
    "test_accuracy6 = accuracy(classifier6, test_set6)\n",
    "\n",
    "# See metrics\n",
    "print(f\"Development test accuracy: {devtest_accuracy6 * 100:.1f}%\")\n",
    "print(f\"Final test accuracy: {test_accuracy6 * 100:.1f}%\")\n",
    "\n",
    "# Most important letter features \n",
    "classifier6.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd227d14-e2b5-453a-95df-75793003a8c6",
   "metadata": {},
   "source": [
    "### The Dev-Test accuracy stayed the same, and the Final Test accuracy rose from 80.4% to 82%. We can see that the most informative features are dominated by the suffixes and the last letter features. This still has the same errors as my gender_features5 classifier, so the edge cases persist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75359c84-724d-451d-bf51-5da8b655904c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 114 out of 500\n",
      "\n",
      "Sample Name Misclassifications:\n",
      "\n",
      "Abagail         - predicted: male   | actual: female\n",
      "Adel            - predicted: male   | actual: female\n",
      "Allah           - predicted: female | actual: male\n",
      "Amabel          - predicted: male   | actual: female\n",
      "Aurel           - predicted: male   | actual: female\n",
      "Bab             - predicted: male   | actual: female\n",
      "Barbey          - predicted: male   | actual: female\n",
      "Barnabe         - predicted: female | actual: male\n",
      "Beau            - predicted: female | actual: male\n",
      "Bell            - predicted: male   | actual: female\n",
      "Beulah          - predicted: male   | actual: female\n",
      "Bren            - predicted: male   | actual: female\n",
      "Brice           - predicted: female | actual: male\n",
      "Bryn            - predicted: female | actual: male\n",
      "Candis          - predicted: male   | actual: female\n",
      "Charleen        - predicted: male   | actual: female\n",
      "Chelsey         - predicted: male   | actual: female\n",
      "Christal        - predicted: male   | actual: female\n",
      "Corey           - predicted: male   | actual: female\n",
      "Cortese         - predicted: female | actual: male\n",
      "Dallas          - predicted: male   | actual: female\n",
      "Darsey          - predicted: male   | actual: female\n",
      "Daryle          - predicted: female | actual: male\n",
      "Davide          - predicted: female | actual: male\n",
      "Dennie          - predicted: female | actual: male\n"
     ]
    }
   ],
   "source": [
    "errors6 = []\n",
    "\n",
    "for (name, true_label) in devtest_names:\n",
    "    guess = classifier6.classify(gender_features6(name))\n",
    "    if guess != true_label:\n",
    "        errors6.append((true_label, guess, name))\n",
    "\n",
    "# Sort errors alphabetically\n",
    "errors6 = sorted(errors6, key=lambda x: x[2])\n",
    "\n",
    "print(f\"Number of errors: {len(errors6)} out of {len(devtest_names)}\")\n",
    "print(\"\\nSample Name Misclassifications:\\n\")\n",
    "\n",
    "for (true_label, guess, name) in errors6[:25]:\n",
    "    print(f\"{name:15} - predicted: {guess:6} | actual: {true_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bd11c65-97cb-43fc-adaf-a127fa87a370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Classifier                                                          Description  Dev-Test Accuracy (%)  Final Test Accuracy (%)  # Errors\n",
      " gender_features                                                     Last letter only                   75.2                     78.6       124\n",
      "gender_features3                            First letter, last 2 letters, name length                   78.2                     82.2       109\n",
      "gender_features4                         First 2 letters, last 2 letters, name length                   79.2                     82.2       104\n",
      "gender_features5 Same as #4, with Vowel & Consonant counts + ending & starting vowels                   77.2                     80.4       114\n",
      "gender_features6                         Same as #5, without Vowel & Consonant counts                   77.2                     82.0       114\n"
     ]
    }
   ],
   "source": [
    "# See metrics for each Naive Bayes Classifier\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Print all columns together\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.precision', 1)\n",
    "\n",
    "# Original Classifier info\n",
    "original_classifiers = [\n",
    "    'gender_features (Last letter only)',\n",
    "    'gender_features3 (First letter, last 2 letters, name length)',\n",
    "    'gender_features4 (First 2 letters, last 2 letters, name length)',\n",
    "    'gender_features5 (Same as #4, with Vowel & Consonant counts + ending & starting vowels)',\n",
    "    'gender_features6 (Same as #5, without Vowel & Consonant counts)'\n",
    "]\n",
    "\n",
    "# Split into Classifier and Description\n",
    "split_classifiers = [c.split('(', 1) for c in original_classifiers]\n",
    "classifier_names = [c[0].strip() for c in split_classifiers]\n",
    "descriptions = [c[1].strip(\") \").strip() if len(c) > 1 else '' for c in split_classifiers]\n",
    "\n",
    "# Create summary table\n",
    "classifier_summary = pd.DataFrame({\n",
    "    'Classifier': classifier_names,\n",
    "    'Description': descriptions,\n",
    "    'Dev-Test Accuracy (%)': [\n",
    "        devtest_accuracy * 100,\n",
    "        devtest_accuracy3 * 100,\n",
    "        devtest_accuracy4 * 100,\n",
    "        devtest_accuracy5 * 100,\n",
    "        devtest_accuracy6 * 100\n",
    "    ],\n",
    "    'Final Test Accuracy (%)': [\n",
    "        test_accuracy * 100,\n",
    "        test_accuracy3 * 100,\n",
    "        test_accuracy4 * 100,\n",
    "        test_accuracy5 * 100,\n",
    "        test_accuracy6 * 100\n",
    "    ],\n",
    "    '# Errors': [\n",
    "        len(errors),\n",
    "        len(errors3),\n",
    "        len(errors4),\n",
    "        len(errors5),\n",
    "        len(errors6)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display table\n",
    "print(classifier_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551cd0bc-d3ba-48a3-9790-737f1e837a10",
   "metadata": {},
   "source": [
    "### Overall, classifier 4 has the best performance using the Naive Bayes method. It assumes features are conditionally independent given the class (Male or Female name), and it counts frequencies of features (like letters in names) for each class. It then uses those counts to compute the probability for the most likely class for each name, then multiplies all those probabilities for each feature together. I want to see how it compares using the Decision Tree and Maximum Entropy Classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a682993-f528-470a-bf9f-dfaea7b992ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (25 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.371\n",
      "             2          -0.43768        0.782\n",
      "             3          -0.37358        0.817\n",
      "             4          -0.34217        0.821\n",
      "             5          -0.32391        0.825\n",
      "             6          -0.31203        0.828\n",
      "             7          -0.30369        0.829\n",
      "             8          -0.29752        0.832\n",
      "             9          -0.29277        0.833\n",
      "            10          -0.28897        0.834\n",
      "            11          -0.28588        0.836\n",
      "            12          -0.28330        0.836\n",
      "            13          -0.28111        0.836\n",
      "            14          -0.27922        0.836\n",
      "            15          -0.27758        0.836\n",
      "            16          -0.27614        0.837\n",
      "            17          -0.27486        0.837\n",
      "            18          -0.27372        0.836\n",
      "            19          -0.27270        0.837\n",
      "            20          -0.27177        0.837\n",
      "            21          -0.27092        0.837\n",
      "            22          -0.27015        0.837\n",
      "            23          -0.26944        0.837\n",
      "            24          -0.26879        0.838\n",
      "         Final          -0.26819        0.838\n",
      "_______________________________________________________________________________\n",
      "   Classifier Dev-Test Accuracy Final Test Accuracy  # Misclassified (Dev-Test)\n",
      "  Naive Bayes            79.20%              82.20%                         104\n",
      "Decision Tree            77.80%              76.80%                         111\n",
      "  Max Entropy            79.20%              82.80%                         104\n"
     ]
    }
   ],
   "source": [
    "from nltk import classify, NaiveBayesClassifier, DecisionTreeClassifier, MaxentClassifier\n",
    "\n",
    "# Best performing NB feature extractor\n",
    "def gender_features4(name):\n",
    "    features = {\n",
    "        'first_letter': name[0].lower(),\n",
    "        'first_two': name[:2].lower(),      \n",
    "        'last_letter': name[-1].lower(),\n",
    "        'last_two': name[-2:].lower(),      \n",
    "        'name_length': len(name)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Prepare feature sets \n",
    "train_set = [(gender_features4(n), g) for (n, g) in train_names]\n",
    "devtest_set = [(gender_features4(n), g) for (n, g) in devtest_names]\n",
    "test_set = [(gender_features4(n), g) for (n, g) in test_names]\n",
    "\n",
    "# Train Classifiers \n",
    "nb_classifier = NaiveBayesClassifier.train(train_set)\n",
    "dt_classifier = DecisionTreeClassifier.train(train_set)\n",
    "me_classifier = MaxentClassifier.train(train_set, max_iter = 25)\n",
    "\n",
    "# Compute Accuracies \n",
    "nb_devtest_acc = classify.accuracy(nb_classifier, devtest_set)\n",
    "nb_test_acc = classify.accuracy(nb_classifier, test_set)\n",
    "\n",
    "dt_devtest_acc = classify.accuracy(dt_classifier, devtest_set)\n",
    "dt_test_acc = classify.accuracy(dt_classifier, test_set)\n",
    "\n",
    "me_devtest_acc = classify.accuracy(me_classifier, devtest_set)\n",
    "me_test_acc = classify.accuracy(me_classifier, test_set)\n",
    "\n",
    "# Count Misclassifications \n",
    "def count_errors(classifier, dataset):\n",
    "    errors = [(name, true) for (features, true), (name, _) in zip(dataset, devtest_names)\n",
    "              if classifier.classify(features) != true]\n",
    "    return len(errors)\n",
    "\n",
    "nb_errors = count_errors(nb_classifier, devtest_set)\n",
    "dt_errors = count_errors(dt_classifier, devtest_set)\n",
    "me_errors = count_errors(me_classifier, devtest_set)\n",
    "\n",
    "print(\"_______________________________________________________________________________\")\n",
    "# Display results\n",
    "results_df = pd.DataFrame({\n",
    "    \"Classifier\": [\"Naive Bayes\", \"Decision Tree\", \"Max Entropy\"],\n",
    "    \"Dev-Test Accuracy\": [f\"{nb_devtest_acc*100:.2f}%\", f\"{dt_devtest_acc*100:.2f}%\", f\"{me_devtest_acc*100:.2f}%\"],\n",
    "    \"Final Test Accuracy\": [f\"{nb_test_acc*100:.2f}%\", f\"{dt_test_acc*100:.2f}%\", f\"{me_test_acc*100:.2f}%\"],\n",
    "    \"# Misclassified (Dev-Test)\": [nb_errors, dt_errors, me_errors]\n",
    "})\n",
    "\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1f2d9-80ce-4a5b-8551-c94d07384e93",
   "metadata": {},
   "source": [
    "### The Decision Tree approach creates rules that split data based on features, where the stronger interactions happen earlier at the splits of each tree node. The Maximum Entropy approach assigns weights to each feature based on how strongly it predicts an observation's label, and can capture overlapping or correlated features better than Naive Bayes. Looking at the results above, we can see that Naive Bayes and Max Entropy models performed about the same. Max Entropy models don't assume independence between the features, unlike Naive Bayes. Overall, these results are quite good and what I'd expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6abd68d-40f5-4e12-88f9-c3ad7d9ad49d",
   "metadata": {},
   "source": [
    "### Out of curiosity, I want to see if n-grams can capture morphological patterns, like -ail, -bel, -die, -ud, -ine that the prior features miss, along with other common gendered substrings such as -ann, -elle, -ette, -ine, and -son. Names like Annette or Madeline will be marked as female names, while names like Jackson and Nathaniel will be marked as male names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "138f62d2-59a2-4c2e-a3fc-b3ab0358e9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (25 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -0.69315        0.371\n",
      "             2          -0.51219        0.690\n",
      "             3          -0.44231        0.819\n",
      "             4          -0.39384        0.865\n",
      "             5          -0.35847        0.880\n",
      "             6          -0.33144        0.889\n",
      "             7          -0.31002        0.895\n",
      "             8          -0.29254        0.901\n",
      "             9          -0.27795        0.906\n",
      "            10          -0.26555        0.908\n",
      "            11          -0.25483        0.912\n",
      "            12          -0.24547        0.914\n",
      "            13          -0.23719        0.917\n",
      "            14          -0.22981        0.920\n",
      "            15          -0.22317        0.922\n",
      "            16          -0.21716        0.923\n",
      "            17          -0.21168        0.924\n",
      "            18          -0.20667        0.925\n",
      "            19          -0.20205        0.927\n",
      "            20          -0.19779        0.928\n",
      "            21          -0.19383        0.929\n",
      "            22          -0.19015        0.930\n",
      "            23          -0.18671        0.931\n",
      "            24          -0.18348        0.932\n",
      "         Final          -0.18045        0.932\n",
      "Development test accuracy: 82.60%\n",
      "Final test accuracy: 85.60%\n",
      "Number of misclassified names (Dev-Test): 87\n",
      "\n",
      "Sample misclassified names (up to 25):\n",
      "Angy            - predicted: male   | actual: female\n",
      "Joe             - predicted: female | actual: male\n",
      "Adrian          - predicted: female | actual: male\n",
      "Chad            - predicted: male   | actual: female\n",
      "Jodie           - predicted: male   | actual: female\n",
      "Blair           - predicted: male   | actual: female\n",
      "Raf             - predicted: male   | actual: female\n",
      "Charlot         - predicted: male   | actual: female\n",
      "Toby            - predicted: female | actual: male\n",
      "Berny           - predicted: male   | actual: female\n",
      "Rubin           - predicted: female | actual: male\n",
      "Clyde           - predicted: female | actual: male\n",
      "Morgan          - predicted: male   | actual: female\n",
      "Willi           - predicted: female | actual: male\n",
      "Blare           - predicted: female | actual: male\n",
      "Paige           - predicted: male   | actual: female\n",
      "Allie           - predicted: female | actual: male\n",
      "Dewey           - predicted: female | actual: male\n",
      "Gretchen        - predicted: male   | actual: female\n",
      "Yuri            - predicted: female | actual: male\n",
      "Doyle           - predicted: female | actual: male\n",
      "Kerry           - predicted: female | actual: male\n",
      "Carlin          - predicted: female | actual: male\n",
      "Duane           - predicted: female | actual: male\n",
      "Mel             - predicted: female | actual: male\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Feature extractor \n",
    "def gender_features_ngrams_substrings(name):\n",
    "    name = name.lower()\n",
    "    features = {}\n",
    "    \n",
    "    # Basic structure features\n",
    "    features['first_letter'] = name[0]\n",
    "    features['last_letter'] = name[-1]\n",
    "    features['name_length'] = len(name)\n",
    "\n",
    "    # Vowel/consonant features\n",
    "    vowels = set('aeiou')\n",
    "    vowel_count = sum(1 for c in name if c in vowels)\n",
    "    consonant_count = len(name) - vowel_count\n",
    "    features['vowel_ratio'] = round(vowel_count / max(1, len(name)), 2)\n",
    "    features['ends_with_vowel'] = name[-1] in vowels\n",
    "    features['vowel_pattern'] = re.sub(r'[^aeiou]', 'C', re.sub(r'[aeiou]', 'V', name))\n",
    "\n",
    "    # Character n-grams up to length 4\n",
    "    for n in range(2, 5):\n",
    "        for i in range(len(name) - n + 1):\n",
    "            gram = name[i:i+n]\n",
    "            features[f'ngram_{n}_{gram}'] = True\n",
    "    \n",
    "    # Gendered substrings\n",
    "    female_substrings = ['ann', 'elle', 'ette', 'ine']\n",
    "    male_substrings = ['son', 'ton', 'ian', 'el']\n",
    "    \n",
    "    for sub in female_substrings:\n",
    "        features[f'has_female_sub_{sub}'] = sub in name\n",
    "    for sub in male_substrings:\n",
    "        features[f'has_male_sub_{sub}'] = sub in name\n",
    "\n",
    "    return features\n",
    "    \n",
    "########################\n",
    "# Load and split the Names corpus\n",
    "male_names = [(name, 'male') for name in names.words('male.txt')]\n",
    "female_names = [(name, 'female') for name in names.words('female.txt')]\n",
    "\n",
    "all_names = male_names + female_names\n",
    "random.shuffle(all_names)\n",
    "\n",
    "test_names = all_names[:500]\n",
    "devtest_names = all_names[500:1000]\n",
    "train_names = all_names[1000:]\n",
    "\n",
    "# Prepare feature sets\n",
    "train_set = [(gender_features_ngrams_substrings(name), gender) for (name, gender) in train_names]\n",
    "devtest_set = [(gender_features_ngrams_substrings(name), gender) for (name, gender) in devtest_names]\n",
    "test_set = [(gender_features_ngrams_substrings(name), gender) for (name, gender) in test_names]\n",
    "\n",
    "# Train Max Entropy Classifier\n",
    "classifier_me = MaxentClassifier.train(train_set, max_iter=25)\n",
    "\n",
    "# Evaluate\n",
    "devtest_accuracy = accuracy(classifier_me, devtest_set)\n",
    "test_accuracy = accuracy(classifier_me, test_set)\n",
    "\n",
    "# Count errors on dev-test\n",
    "errors = [(true, guess, name) for (name, true) in devtest_names\n",
    "          if (guess := classifier_me.classify(gender_features_ngrams_substrings(name))) != true]\n",
    "\n",
    "\n",
    "# Display results\n",
    "print(f\"Development test accuracy: {devtest_accuracy*100:.2f}%\")\n",
    "print(f\"Final test accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"Number of misclassified names (Dev-Test): {len(errors)}\\n\")\n",
    "\n",
    "print(\"Sample misclassified names (up to 25):\")\n",
    "for (true_label, guess, name) in errors[:25]:\n",
    "    print(f\"{name:15} - predicted: {guess:6} | actual: {true_label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7058a4-d29f-4afb-8810-8d15d990dd67",
   "metadata": {},
   "source": [
    "### This feature extractor is an improvement from the prior one, with rises in Dev-Test accuracy (79.2% to 82.6%), and Final Test accuracy (82.8% to 85.6%), making fewer mistakes on name classifying (87 vs 104)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
