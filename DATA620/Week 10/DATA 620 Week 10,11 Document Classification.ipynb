{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba05707-ee20-44ac-a358-299d0bb6b726",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "\n",
    "### It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set (https://archive.ics.uci.edu/dataset/94/spambase)\n",
    "\n",
    "### For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source, such as your own spam folder).\n",
    "\n",
    "### For more adventurous students, you are welcome (encouraged!) to come up with a different set of documents (including scraped web pages) that have already been classified (e.g., tagged), then analyze these documents to predict how new documents should be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f58d903-1f7d-4d7b-a6bd-908a1ac2340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 94, 'name': 'Spambase', 'repository_url': 'https://archive.ics.uci.edu/dataset/94/spambase', 'data_url': 'https://archive.ics.uci.edu/static/public/94/data.csv', 'abstract': 'Classifying Email as Spam or Non-Spam', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 4601, 'num_features': 57, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1999, 'last_updated': 'Mon Aug 28 2023', 'dataset_doi': '10.24432/C53G6X', 'creators': ['Mark Hopkins', 'Erik Reeber', 'George Forman', 'Jaap Suermondt'], 'intro_paper': None, 'additional_info': {'summary': 'The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\\n\\nThe classification task for this dataset is to determine whether a given email is spam or not.\\n\\t\\nOur collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word \\'george\\' and the area code \\'650\\' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\\n\\nFor background on spam: Cranor, Lorrie F., LaMacchia, Brian A.  Spam!, Communications of the ACM, 41(8):74-83, 1998.\\n\\nTypical performance is around ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter. See also Hewlett-Packard Internal-only Technical Report. External version forthcoming. ', 'purpose': None, 'funded_by': None, 'instances_represent': 'Emails', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'The last column of \\'spambase.data\\' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail.  The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  For the statistical measures of each attribute, see the end of this file.  Here are the definitions of the attributes:\\r\\n\\r\\n48 continuous real [0,100] attributes of type word_freq_WORD \\r\\n= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\\r\\n\\r\\n6 continuous real [0,100] attributes of type char_freq_CHAR] \\r\\n= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\\r\\n\\r\\n1 continuous real [1,...] attribute of type capital_run_length_average \\r\\n= average length of uninterrupted sequences of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_longest \\r\\n= length of longest uninterrupted sequence of capital letters\\r\\n\\r\\n1 continuous integer [1,...] attribute of type capital_run_length_total \\r\\n= sum of length of uninterrupted sequences of capital letters \\r\\n= total number of capital letters in the e-mail\\r\\n\\r\\n1 nominal {0,1} class attribute of type spam\\r\\n= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \\r\\n', 'citation': None}}\n",
      "                          name     role        type demographic  \\\n",
      "0               word_freq_make  Feature  Continuous        None   \n",
      "1            word_freq_address  Feature  Continuous        None   \n",
      "2                word_freq_all  Feature  Continuous        None   \n",
      "3                 word_freq_3d  Feature  Continuous        None   \n",
      "4                word_freq_our  Feature  Continuous        None   \n",
      "5               word_freq_over  Feature  Continuous        None   \n",
      "6             word_freq_remove  Feature  Continuous        None   \n",
      "7           word_freq_internet  Feature  Continuous        None   \n",
      "8              word_freq_order  Feature  Continuous        None   \n",
      "9               word_freq_mail  Feature  Continuous        None   \n",
      "10           word_freq_receive  Feature  Continuous        None   \n",
      "11              word_freq_will  Feature  Continuous        None   \n",
      "12            word_freq_people  Feature  Continuous        None   \n",
      "13            word_freq_report  Feature  Continuous        None   \n",
      "14         word_freq_addresses  Feature  Continuous        None   \n",
      "15              word_freq_free  Feature  Continuous        None   \n",
      "16          word_freq_business  Feature  Continuous        None   \n",
      "17             word_freq_email  Feature  Continuous        None   \n",
      "18               word_freq_you  Feature  Continuous        None   \n",
      "19            word_freq_credit  Feature  Continuous        None   \n",
      "20              word_freq_your  Feature  Continuous        None   \n",
      "21              word_freq_font  Feature  Continuous        None   \n",
      "22               word_freq_000  Feature  Continuous        None   \n",
      "23             word_freq_money  Feature  Continuous        None   \n",
      "24                word_freq_hp  Feature  Continuous        None   \n",
      "25               word_freq_hpl  Feature  Continuous        None   \n",
      "26            word_freq_george  Feature  Continuous        None   \n",
      "27               word_freq_650  Feature  Continuous        None   \n",
      "28               word_freq_lab  Feature  Continuous        None   \n",
      "29              word_freq_labs  Feature  Continuous        None   \n",
      "30            word_freq_telnet  Feature  Continuous        None   \n",
      "31               word_freq_857  Feature  Continuous        None   \n",
      "32              word_freq_data  Feature  Continuous        None   \n",
      "33               word_freq_415  Feature  Continuous        None   \n",
      "34                word_freq_85  Feature  Continuous        None   \n",
      "35        word_freq_technology  Feature  Continuous        None   \n",
      "36              word_freq_1999  Feature  Continuous        None   \n",
      "37             word_freq_parts  Feature  Continuous        None   \n",
      "38                word_freq_pm  Feature  Continuous        None   \n",
      "39            word_freq_direct  Feature  Continuous        None   \n",
      "40                word_freq_cs  Feature  Continuous        None   \n",
      "41           word_freq_meeting  Feature  Continuous        None   \n",
      "42          word_freq_original  Feature  Continuous        None   \n",
      "43           word_freq_project  Feature  Continuous        None   \n",
      "44                word_freq_re  Feature  Continuous        None   \n",
      "45               word_freq_edu  Feature  Continuous        None   \n",
      "46             word_freq_table  Feature  Continuous        None   \n",
      "47        word_freq_conference  Feature  Continuous        None   \n",
      "48                 char_freq_;  Feature  Continuous        None   \n",
      "49                 char_freq_(  Feature  Continuous        None   \n",
      "50                 char_freq_[  Feature  Continuous        None   \n",
      "51                 char_freq_!  Feature  Continuous        None   \n",
      "52                 char_freq_$  Feature  Continuous        None   \n",
      "53                 char_freq_#  Feature  Continuous        None   \n",
      "54  capital_run_length_average  Feature  Continuous        None   \n",
      "55  capital_run_length_longest  Feature  Continuous        None   \n",
      "56    capital_run_length_total  Feature  Continuous        None   \n",
      "57                       Class   Target      Binary        None   \n",
      "\n",
      "                 description units missing_values  \n",
      "0                       None  None             no  \n",
      "1                       None  None             no  \n",
      "2                       None  None             no  \n",
      "3                       None  None             no  \n",
      "4                       None  None             no  \n",
      "5                       None  None             no  \n",
      "6                       None  None             no  \n",
      "7                       None  None             no  \n",
      "8                       None  None             no  \n",
      "9                       None  None             no  \n",
      "10                      None  None             no  \n",
      "11                      None  None             no  \n",
      "12                      None  None             no  \n",
      "13                      None  None             no  \n",
      "14                      None  None             no  \n",
      "15                      None  None             no  \n",
      "16                      None  None             no  \n",
      "17                      None  None             no  \n",
      "18                      None  None             no  \n",
      "19                      None  None             no  \n",
      "20                      None  None             no  \n",
      "21                      None  None             no  \n",
      "22                      None  None             no  \n",
      "23                      None  None             no  \n",
      "24                      None  None             no  \n",
      "25                      None  None             no  \n",
      "26                      None  None             no  \n",
      "27                      None  None             no  \n",
      "28                      None  None             no  \n",
      "29                      None  None             no  \n",
      "30                      None  None             no  \n",
      "31                      None  None             no  \n",
      "32                      None  None             no  \n",
      "33                      None  None             no  \n",
      "34                      None  None             no  \n",
      "35                      None  None             no  \n",
      "36                      None  None             no  \n",
      "37                      None  None             no  \n",
      "38                      None  None             no  \n",
      "39                      None  None             no  \n",
      "40                      None  None             no  \n",
      "41                      None  None             no  \n",
      "42                      None  None             no  \n",
      "43                      None  None             no  \n",
      "44                      None  None             no  \n",
      "45                      None  None             no  \n",
      "46                      None  None             no  \n",
      "47                      None  None             no  \n",
      "48                      None  None             no  \n",
      "49                      None  None             no  \n",
      "50                      None  None             no  \n",
      "51                      None  None             no  \n",
      "52                      None  None             no  \n",
      "53                      None  None             no  \n",
      "54                      None  None             no  \n",
      "55                      None  None             no  \n",
      "56                      None  None             no  \n",
      "57  spam (1) or not spam (0)  None             no  \n"
     ]
    }
   ],
   "source": [
    "#pip install ucimlrepo\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "spambase = fetch_ucirepo(id=94) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = spambase.data.features \n",
    "y = spambase.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(spambase.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(spambase.variables) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd819aaa-9fce-404c-a83c-e558d93718cc",
   "metadata": {},
   "source": [
    "### X contains 57 numeric features (word frequencies, character frequencies, capitalization stats, etc.)\n",
    "\n",
    "### y  contains the binary target variable (1 = spam, 0 = not spam)\n",
    "\n",
    "### There are 4601 email samples, and their stated typical performance is around ~7% misclassification error. The dataset is small and already numeric, so no text preprocessing is needed here, and I can begin model training and evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb616f88-5675-4c7d-ab0b-33d5d674d494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data: 80% for training, 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b018feff-220a-470c-8cba-aaa69a4f5de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae908a175ba48a4908aa1f0c702e307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Models:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison Results:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Spam=1)</th>\n",
       "      <th>Recall (Spam=1)</th>\n",
       "      <th>F1-score (Spam=1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.926167</td>\n",
       "      <td>0.935135</td>\n",
       "      <td>0.887179</td>\n",
       "      <td>0.910526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Max Entropy (Logistic Regression)</td>\n",
       "      <td>0.919653</td>\n",
       "      <td>0.931694</td>\n",
       "      <td>0.874359</td>\n",
       "      <td>0.902116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.918567</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.901961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.820847</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.946154</td>\n",
       "      <td>0.817276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  Accuracy  Precision (Spam=1)  \\\n",
       "0             Support Vector Machine  0.926167            0.935135   \n",
       "1  Max Entropy (Logistic Regression)  0.919653            0.931694   \n",
       "2                      Decision Tree  0.918567            0.920000   \n",
       "3                        Naive Bayes  0.820847            0.719298   \n",
       "\n",
       "   Recall (Spam=1)  F1-score (Spam=1)  \n",
       "0         0.887179           0.910526  \n",
       "1         0.874359           0.902116  \n",
       "2         0.884615           0.901961  \n",
       "3         0.946154           0.817276  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classifier training \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm.notebook import tqdm  # progress bar\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten y to avoid DataConversionWarning\n",
    "y_train_flat = y_train.values.ravel()\n",
    "y_test_flat = y_test.values.ravel()\n",
    "\n",
    "# Scale features for SVM and Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Max Entropy (Logistic Regression)\": LogisticRegression(max_iter=5000, random_state=42),\n",
    "    \"Support Vector Machine\": SVC(kernel='linear', random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Add progress bar\n",
    "for name, model in tqdm(models.items(), desc=\"Training Models\"):\n",
    "    # Use scaled features for models sensitive to feature magnitude\n",
    "    if name in [\"Max Entropy (Logistic Regression)\", \"Support Vector Machine\"]:\n",
    "        model.fit(X_train_scaled, y_train_flat)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train_flat)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test_flat, y_pred)\n",
    "    report = classification_report(y_test_flat, y_pred, output_dict=True)\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision (Spam=1)\": report['1']['precision'],\n",
    "        \"Recall (Spam=1)\": report['1']['recall'],\n",
    "        \"F1-score (Spam=1)\": report['1']['f1-score']\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).sort_values(by=\"Accuracy\", ascending=False).reset_index(drop=True)\n",
    "print(\"Model Comparison Results:\\n\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "886500c2-142b-4226-bd1c-adf3c3f05380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 5-Fold CV for Linear SVM ...\n",
      "Running 5-Fold CV for Max Entropy (Logistic Regression) ...\n",
      "Running 5-Fold CV for Decision Tree ...\n",
      "Running 5-Fold CV for Naive Bayes ...\n",
      "\n",
      "Cross-Validation Results (5-Fold):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Mean</th>\n",
       "      <th>Accuracy Std</th>\n",
       "      <th>Precision Mean</th>\n",
       "      <th>Recall Mean</th>\n",
       "      <th>F1 Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Max Entropy (Logistic Regression)</td>\n",
       "      <td>0.925019</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.920916</td>\n",
       "      <td>0.886355</td>\n",
       "      <td>0.903028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.924801</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.921365</td>\n",
       "      <td>0.885250</td>\n",
       "      <td>0.902665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.906327</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.876786</td>\n",
       "      <td>0.887469</td>\n",
       "      <td>0.881878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.791565</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>0.743051</td>\n",
       "      <td>0.721469</td>\n",
       "      <td>0.731883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Model  Accuracy Mean  Accuracy Std  \\\n",
       "1  Max Entropy (Logistic Regression)       0.925019      0.006116   \n",
       "0                         Linear SVM       0.924801      0.005574   \n",
       "2                      Decision Tree       0.906327      0.006282   \n",
       "3                        Naive Bayes       0.791565      0.013040   \n",
       "\n",
       "   Precision Mean  Recall Mean   F1 Mean  \n",
       "1        0.920916     0.886355  0.903028  \n",
       "0        0.921365     0.885250  0.902665  \n",
       "2        0.876786     0.887469  0.881878  \n",
       "3        0.743051     0.721469  0.731883  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cross-validation to confirm accuracy score stability\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Scale features for SVM and Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define stratified k-fold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Linear SVM\": LinearSVC(max_iter=10000, random_state=42, dual=False),\n",
    "    \"Max Entropy (Logistic Regression)\": LogisticRegression(max_iter=5000, random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Naive Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "# Store results\n",
    "cv_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Running 5-Fold CV for {name} ...\")\n",
    "    \n",
    "    # Use scaled data for Linear SVM and Logistic Regression\n",
    "    if name in [\"Linear SVM\", \"Max Entropy (Logistic Regression)\"]:\n",
    "        X_use = X_scaled\n",
    "    else:\n",
    "        X_use = X\n",
    "    \n",
    "    accuracy = cross_val_score(model, X_use, np.ravel(y), cv=kfold, scoring='accuracy')\n",
    "    precision = cross_val_score(model, X_use, np.ravel(y), cv=kfold, scoring=make_scorer(precision_score))\n",
    "    recall = cross_val_score(model, X_use, np.ravel(y), cv=kfold, scoring=make_scorer(recall_score))\n",
    "    f1 = cross_val_score(model, X_use, np.ravel(y), cv=kfold, scoring=make_scorer(f1_score))\n",
    "    \n",
    "    cv_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy Mean\": np.mean(accuracy),\n",
    "        \"Accuracy Std\": np.std(accuracy),\n",
    "        \"Precision Mean\": np.mean(precision),\n",
    "        \"Recall Mean\": np.mean(recall),\n",
    "        \"F1 Mean\": np.mean(f1)\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "cv_df = pd.DataFrame(cv_results)\n",
    "print(\"\\nCross-Validation Results (5-Fold):\")\n",
    "display(cv_df.sort_values(by=\"Accuracy Mean\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780bc3c-6d05-4b8d-a1a3-901cb305e954",
   "metadata": {},
   "source": [
    "### Overall, Linear Support Vector Machines and Logistic Regression perform nearly identically, with a high 92.5% accuracy and low standard deviations, hence the models are stable. Precision checks the proportion of all the emails predicted as spam, what fraction actually were spam (True Positive). Recall checks the proportion of all actual spam emails, what fraction was identified correctly. These metrics are 92.1% and 88.6% respectively, so the Max Entropy and SVM models rarely label good emails as spam and catch most actual spam emails. F1 is the balanced harmonic mean of these two metrics, and is 90% for both. Now the model is trained, cross-validated, and ready to be used with new data. I will use Kaggle's SMS Spam collection dataset, to see how a model trained on email data performs with text-message data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ff2e0e-cc3b-4e88-9986-aa3c8c345041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\sms-spam-collection-dataset\" (use force=True to force download)\n",
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# This requires Kaggle username and key: http://bit.ly/kaggle-creds\n",
    "# Define the .kaggle folder\n",
    "kaggle_folder = os.path.join(os.path.expanduser(\"~\"), \".kaggle\")\n",
    "os.makedirs(kaggle_folder, exist_ok=True)\n",
    "\n",
    "# Copy kaggle.json to new location\n",
    "shutil.copy(r\"C:\\Users\\Ron\\OneDrive\\Desktop\\kaggle.json\", os.path.join(kaggle_folder, \"kaggle.json\"))\n",
    "\n",
    "# Fetch data using credentials in kaggle.json\n",
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/uciml/sms-spam-collection-dataset\")\n",
    "\n",
    "# Load Data\n",
    "kaggle_df = pd.read_csv(r\"sms-spam-collection-dataset\\spam.csv\", encoding='latin-1')  \n",
    "# Keep only relevant columns and rename\n",
    "kaggle_df = kaggle_df[['v1','v2']].rename(columns={'v1':'Category','v2':'Message'})\n",
    "print(kaggle_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07cf241-2b6f-4af3-a8bd-451670c910e7",
   "metadata": {},
   "source": [
    "### The SMS data has been loaded from Kaggle, and the features in my original Spambase dataset are different from raw SMS text, so I need to vectorize the SMS messages into the same feature format as the training data. Spambase is numeric (word/char frequencies), so thereâ€™s no direct 1-to-1 mapping for SMS text. The original SVM trained on spambase can't be used directly on SMS text, as this new data doesn't have the original 57 numeric features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1d93587-0340-4760-b8c4-5feb9c65dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Spambase features from Kaggle SMS Messages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# List of words from Spambase features\n",
    "spambase_words = [\n",
    "    \"make\", \"address\", \"all\", \"3d\", \"our\", \"over\", \"remove\", \"internet\", \n",
    "    \"order\", \"mail\", \"receive\", \"will\", \"people\", \"report\", \"addresses\", \n",
    "    \"free\", \"business\", \"email\", \"you\", \"credit\", \"your\", \"font\", \"000\",\n",
    "    \"money\", \"hp\", \"hpl\", \"george\", \"650\", \"lab\", \"labs\", \"telnet\", \"857\",\n",
    "    \"data\", \"415\", \"85\", \"technology\", \"1999\", \"parts\", \"pm\", \"direct\",\n",
    "    \"cs\", \"meeting\", \"original\", \"project\", \"re\", \"edu\", \"table\", \"conference\"\n",
    "]\n",
    "\n",
    "# List of characters for char_freq features\n",
    "spambase_chars = [';', '(', '[', '!', '$', '#']\n",
    "\n",
    "def compute_spambase_features(message):\n",
    "    message_lower = message.lower()\n",
    "    total_words = len(re.findall(r'\\b\\w+\\b', message_lower)) or 1\n",
    "    total_chars = len(message) or 1\n",
    "    \n",
    "    features = []\n",
    "\n",
    "    # Word frequencies\n",
    "    for w in spambase_words:\n",
    "        freq = 100 * message_lower.split().count(w) / total_words\n",
    "        features.append(freq)\n",
    "    \n",
    "    # Char frequencies\n",
    "    for c in spambase_chars:\n",
    "        freq = 100 * message.count(c) / total_chars\n",
    "        features.append(freq)\n",
    "    \n",
    "    # Capital run lengths\n",
    "    caps = re.findall(r'[A-Z]+', message)\n",
    "    if caps:\n",
    "        lengths = [len(seq) for seq in caps]\n",
    "        # capital_run_length_average\n",
    "        features.append(np.mean(lengths))  \n",
    "        # capital_run_length_longest\n",
    "        features.append(np.max(lengths)) \n",
    "        # capital_run_length_total\n",
    "        features.append(np.sum(lengths))         \n",
    "    else:\n",
    "        features.extend([0, 0, 0])\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a3fb4e7-02b3-45f8-a9fc-4c2ab3d097d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of SMS features: (5572, 57)\n",
      "Shape expected by scaler: (4601, 57)\n"
     ]
    }
   ],
   "source": [
    "# Fit the SVM on the full Spambase training data\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fit scaler on Spambase features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # X from Spambase\n",
    "\n",
    "# Fit LinearSVC on the full dataset\n",
    "svm_model = LinearSVC(max_iter=10000, random_state=42, dual=False)\n",
    "svm_model.fit(X_scaled, np.ravel(y))  # y from Spambase\n",
    "\n",
    "# Compute features for all SMS messages\n",
    "X_sms_features = np.array([compute_spambase_features(msg) for msg in kaggle_df['Message']])\n",
    "\n",
    "# Check shape of Spambase and Kaggle SMS features\n",
    "print(\"Shape of SMS features:\", X_sms_features.shape)\n",
    "print(\"Shape expected by scaler:\", X_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb4ee71-a762-45c0-a451-73e233042d24",
   "metadata": {},
   "source": [
    "### With the features prepped, I can get predictions and accuracy metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa284dff-01e6-440f-ac44-b560a20b08ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category                                            Message Predicted_Label\n",
      "0      ham  Go until jurong point, crazy.. Available only ...             ham\n",
      "1      ham                      Ok lar... Joking wif u oni...             ham\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...            spam\n",
      "3      ham  U dun say so early hor... U c already then say...             ham\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...             ham\n",
      "5     spam  FreeMsg Hey there darling it's been 3 week's n...             ham\n",
      "6      ham  Even my brother is not like to speak with me. ...             ham\n",
      "7      ham  As per your request 'Melle Melle (Oru Minnamin...            spam\n",
      "8     spam  WINNER!! As a valued network customer you have...             ham\n",
      "9     spam  Had your mobile 11 months or more? U R entitle...            spam\n",
      "_________________________________________________________\n",
      "SMS Spam Prediction Metrics (using Spambase-trained SVM):\n",
      "Accuracy : 0.8110\n",
      "Precision: 0.3273\n",
      "Recall   : 0.3882\n",
      "F1-score : 0.3552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ron\\anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Scale SMS features with the same scaler\n",
    "X_sms_scaled = scaler.transform(X_sms_features)\n",
    "# Predictions\n",
    "predictions = svm_model.predict(X_sms_scaled)\n",
    "\n",
    "kaggle_df['Predicted'] = predictions\n",
    "kaggle_df['Predicted_Label'] = kaggle_df['Predicted'].map({0: 'ham', 1: 'spam'})\n",
    "print(kaggle_df[['Category', 'Message', 'Predicted_Label']].head(10))\n",
    "\n",
    "# Get metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# True labels\n",
    "y_true = (kaggle_df['Category'] == 'spam').astype(int)\n",
    "\n",
    "# Predicted labels\n",
    "y_pred = kaggle_df['Predicted']\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(\"_________________________________________________________\")\n",
    "print(\"SMS Spam Prediction Metrics (using Spambase-trained SVM):\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf51a6-66ac-473a-ade9-f2606b07b6bc",
   "metadata": {},
   "source": [
    "### Looking at the results, I see that the SVM which was trained on Spambase's Email data doesn't perform as well on SMS text data. This is because the dataset is imbalanced, with more instances of non-spam than spam, and the feature distributions such as word usage, character length, and general linguistic structure of informal text messages throws off the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
